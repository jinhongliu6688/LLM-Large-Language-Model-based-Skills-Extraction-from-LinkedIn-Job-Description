{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrbFsgi4rd6G"
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "#import codecs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AmDceburd6K"
   },
   "outputs": [],
   "source": [
    "path = \"Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_segment</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SummaryThe Database Developer is part of the C...</td>\n",
       "      <td>CEMCO, C#, database performance, .Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Perform database security administration.Ensur...</td>\n",
       "      <td>C#, .Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Education And/Or Experience, Certifications, R...</td>\n",
       "      <td>teamwork, Project management, SQL, T-SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Physical DemandsWhile performing the duties of...</td>\n",
       "      <td>close vision, distance vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>CEMCO, LLC, is the premier manufacturer of ste...</td>\n",
       "      <td>CEMCO, LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>6686</td>\n",
       "      <td>6686</td>\n",
       "      <td>1840</td>\n",
       "      <td>Sr. Full Stack DeveloperWelcome to Beaker &amp; Wr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>6687</td>\n",
       "      <td>6687</td>\n",
       "      <td>1840</td>\n",
       "      <td>We need a full-stack developer who is a self-s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>6688</td>\n",
       "      <td>6688</td>\n",
       "      <td>1840</td>\n",
       "      <td>The desired developer will head development an...</td>\n",
       "      <td>HTML, Wordpress, Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6677</th>\n",
       "      <td>6689</td>\n",
       "      <td>6689</td>\n",
       "      <td>1841</td>\n",
       "      <td>Become part of one of a large, high-performing...</td>\n",
       "      <td>CI/CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>6690</td>\n",
       "      <td>6690</td>\n",
       "      <td>1841</td>\n",
       "      <td>What should you have?4 Years working in a tech...</td>\n",
       "      <td>CI/CD, Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6679 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0  job_id  \\\n",
       "0         0           0       0   \n",
       "1         1           1       0   \n",
       "2         2           2       0   \n",
       "3         3           3       0   \n",
       "4         4           4       0   \n",
       "...     ...         ...     ...   \n",
       "6674   6686        6686    1840   \n",
       "6675   6687        6687    1840   \n",
       "6676   6688        6688    1840   \n",
       "6677   6689        6689    1841   \n",
       "6678   6690        6690    1841   \n",
       "\n",
       "                                            job_segment  \\\n",
       "0     SummaryThe Database Developer is part of the C...   \n",
       "1     Perform database security administration.Ensur...   \n",
       "2     Education And/Or Experience, Certifications, R...   \n",
       "3     Physical DemandsWhile performing the duties of...   \n",
       "4     CEMCO, LLC, is the premier manufacturer of ste...   \n",
       "...                                                 ...   \n",
       "6674  Sr. Full Stack DeveloperWelcome to Beaker & Wr...   \n",
       "6675  We need a full-stack developer who is a self-s...   \n",
       "6676  The desired developer will head development an...   \n",
       "6677  Become part of one of a large, high-performing...   \n",
       "6678  What should you have?4 Years working in a tech...   \n",
       "\n",
       "                                        skills  \n",
       "0        CEMCO, C#, database performance, .Net  \n",
       "1                                     C#, .Net  \n",
       "2     teamwork, Project management, SQL, T-SQL  \n",
       "3                close vision, distance vision  \n",
       "4                                   CEMCO, LLC  \n",
       "...                                        ...  \n",
       "6674                                       NaN  \n",
       "6675                                       NaN  \n",
       "6676                   HTML, Wordpress, Python  \n",
       "6677                                     CI/CD  \n",
       "6678                             CI/CD, Python  \n",
       "\n",
       "[6679 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'GPT-3_data_split_into_128_word_paragraphs.csv')\n",
    "df = df[~df['job_segment'].isna()].reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data to BIO tags notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(job, skills):\n",
    "    try:\n",
    "        doc = nlp(job)\n",
    "    except:\n",
    "        print(job)\n",
    "    tokens  = [str(i) for i in doc]\n",
    "    tags = ['O' for i in tokens]\n",
    "    if type(skills) != float:\n",
    "        try:\n",
    "            skills = [i.strip() for i in skills.split(',')]\n",
    "        except:\n",
    "            print(skills)\n",
    "        for skill in skills:\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token == skill:\n",
    "                    tags[i] = 'B'\n",
    "                unigrams = skill.split()\n",
    "                if len(unigrams) > 1:\n",
    "                    if i< len(tokens)-1 and token == unigrams[0] and tokens[i+1] == unigrams[1]:\n",
    "                        tags[i] = 'B'\n",
    "                        tags[i+1] = 'I'\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, tags = get_tags(df['job_segment'][0],  df['skills'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for token, tag in zip(tokens, tags):\n",
    "    if tag in {'B', 'I'}:\n",
    "        print(token, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6679it [02:27, 45.14it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "all_tags = []\n",
    "for job, skills in tqdm(zip(df['job_segment'], df['skills'])):\n",
    "    tokens, tags = get_tags(job, skills)\n",
    "    all_tokens.append(tokens)\n",
    "    all_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting the input token length to 200 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the longest sentence\n",
    "LONGEST_SENTENCE = 200\n",
    "LONGEST_SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5669"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens, output_tags = [], []\n",
    "for i, j in zip(all_tokens, all_tags):\n",
    "    if len(i) <= LONGEST_SENTENCE:\n",
    "        input_tokens.append(i)\n",
    "        output_tags.append(j)\n",
    "len(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjayFFzsrd6s"
   },
   "outputs": [],
   "source": [
    "def pad_tokens(input_tokens, longest_sentence):\n",
    "    padded = []\n",
    "    for sent in input_tokens:\n",
    "        padding = [\"<null>\" for i in range(longest_sentence - len(sent))]\n",
    "        padded.append(sent + padding)\n",
    "    return padded\n",
    "\n",
    "def pad_tags(output_tags, longest_sentence):\n",
    "    padded = []\n",
    "    for sent in output_tags:\n",
    "        padding = [ \"<null>\" for i in range(longest_sentence - len(sent))]\n",
    "        padded.append(sent + padding)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVoe-A39rd6u",
    "outputId": "f1c90533-1868-4b04-f8e5-8da93dd64bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "padded_input_tokens = pad_tokens(input_tokens[0:1], LONGEST_SENTENCE) \n",
    "padded_output_tags = pad_tags(output_tags[0:1], LONGEST_SENTENCE)\n",
    "\n",
    "assert len(padded_input_tokens[0]) == LONGEST_SENTENCE\n",
    "assert len(padded_output_tags[0]) == LONGEST_SENTENCE\n",
    "assert padded_input_tokens[0][-1] == \"<null>\"\n",
    "assert padded_output_tags[0][-1] == \"<null>\" \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceIZb3Sprd6x"
   },
   "source": [
    "Now, we need to vectorize our input vocabulary and output tags. The code below creates a number of global variables to help us with this. \n",
    "\n",
    "* The `WORD_TO_IDX` dictionary maps words occurring in the training data into unique integers. \n",
    "* The `TAG_TO_IDX` dictionary maps *every* tag in our data to a unique integer. \n",
    "* The `IDX_TO_TAG` dictionary maps the other way so you can decode tags later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TySaTC7urd6y"
   },
   "outputs": [],
   "source": [
    "PAD = \"<null>\"\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "words = set([word for sent_words in input_tokens for word in sent_words])\n",
    "\n",
    "# Padding and unknown token\n",
    "words.add(PAD)\n",
    "words.add(UNK)\n",
    "\n",
    "tags = list(set([tag for sent_tags in output_tags for tag in sent_tags]))\n",
    "\n",
    "# Padding tag\n",
    "tags.append(PAD)\n",
    "\n",
    "WORD_TO_IDX = {w:i for i,w in enumerate(words)}\n",
    "TAG_TO_IDX = {t:i for i,t in enumerate(tags)}\n",
    "IDX_TO_TAG = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33850"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WORD_TO_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0, 'O': 1, 'I': 2, '<null>': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG_TO_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Qe5VPxPrd64"
   },
   "outputs": [],
   "source": [
    "def converttokens2tensors(input_tokens):\n",
    "    '''\n",
    "        Convert input_tokens into a tensor\n",
    "        \n",
    "        input:  A list of sentences consisting of (token, is_target_pred) pairs.\n",
    "        output: A list of 2 x sentence_length tensor t\n",
    "        \n",
    "        where t[0][i] gives the index number for token i, t[1][i] is either 0 or 1 \n",
    "        depending on is_target_pred and t[2][i] indicates whether this is a regular\n",
    "        token or padding token PAD.\n",
    "    '''\n",
    "    token_tensors = []\n",
    "    #your code here\n",
    "    unk = WORD_TO_IDX[\"<unk>\"]\n",
    "\n",
    "    for sent in input_tokens:\n",
    "        tokens = [i for i in sent]\n",
    "        ids = [WORD_TO_IDX[token] if token in WORD_TO_IDX else WORD_TO_IDX['<unk>'] for token in tokens]\n",
    "        pad_status = [1 if i!='<null>' else 0 for i in tokens]\n",
    "        t =  torch.tensor([ids, pad_status])\n",
    "        token_tensors.append(t)\n",
    "    \n",
    "    return token_tensors\n",
    "\n",
    "def converttags2tensors(output_tags):\n",
    "    '''\n",
    "        Convert output_tags into a tensor\n",
    "\n",
    "        input:  A list of IOB tag sequences.\n",
    "        output: A list of vectors of index numbers correspinding to IOB tags \n",
    "    '''\n",
    "    tag_tensors = []\n",
    "    #your code here\n",
    "    for sent in output_tags:\n",
    "        t = torch.tensor([TAG_TO_IDX[i] for i in sent]) \n",
    "        tag_tensors.append(t)\n",
    "   \n",
    "    return tag_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assertions to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4e0PSFqUrd67",
    "outputId": "65f5c69c-3750-47c4-9284-18833582d02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "check_tokens, check_tags = converttokens2tensors(padded_input_tokens[:5]), converttags2tensors(padded_output_tags[:5])\n",
    "assert check_tokens[0].shape == torch.Size([2, LONGEST_SENTENCE])\n",
    "assert check_tags[0].shape == torch.Size([LONGEST_SENTENCE])\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tran, test and dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dev_index = random.sample(range(len(input_tokens)), 2000)\n",
    "dev_index = random.sample(test_dev_index, 1000)\n",
    "test_index = [i for i in test_dev_index if i not in dev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = [v for i, v in enumerate(input_tokens) if i not in test_dev_index]\n",
    "train_output = [v for i, v in enumerate(output_tags) if i not in test_dev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummaryThe , O\n",
      "Database , O\n",
      "Developer , O\n",
      "is , O\n",
      "part , O\n",
      "of , O\n",
      "the , O\n",
      "CEMCO , B\n",
      "development , O\n",
      "team , O\n",
      "whose , O\n",
      "responsibilities , O\n",
      "include , O\n",
      "managing , O\n",
      "and , O\n",
      "maintaining , O\n",
      "the , O\n",
      "enterprise , O\n",
      "data , O\n",
      "warehouse , O\n",
      ". , O\n",
      "Strong , O\n",
      "development , O\n",
      "skills , O\n",
      "in , O\n",
      "C , O\n",
      "# , O\n",
      "and , O\n",
      ".Net , B\n",
      ", , O\n",
      "including , O\n",
      "Excel , O\n",
      "VSTO.The , O\n",
      "ideal , O\n",
      "candidate , O\n",
      "should , O\n",
      "have , O\n",
      "a , O\n",
      "deep , O\n",
      "understanding , O\n",
      "of , O\n",
      "database , O\n",
      "management , O\n",
      "systems , O\n",
      ", , O\n",
      "as , O\n",
      "well , O\n",
      "as , O\n",
      "the , O\n",
      "ability , O\n",
      "to , O\n",
      "write , O\n",
      "complex , O\n",
      "code , O\n",
      "in , O\n",
      "C , O\n",
      "# , O\n",
      "and , O\n",
      ".Net , B\n",
      "to , O\n",
      "build , O\n",
      ", , O\n",
      "maintain , O\n",
      "and , O\n",
      "optimize , O\n",
      "databases , O\n",
      ". , O\n",
      "Effective , O\n",
      "at , O\n",
      "communicating , O\n",
      "with , O\n",
      "users , O\n",
      "to , O\n",
      "define , O\n",
      "requirements , O\n",
      "and , O\n",
      "design , O\n",
      ", , O\n",
      "solutions , O\n",
      "based , O\n",
      "on , O\n",
      "those , O\n",
      "requirements , O\n",
      ". , O\n",
      "This , O\n",
      "position , O\n",
      "is , O\n",
      "also , O\n",
      "responsible , O\n",
      "for , O\n",
      "creating , O\n",
      "tools , O\n",
      "that , O\n",
      "provide , O\n",
      "insight , O\n",
      "to , O\n",
      "various , O\n",
      "departments , O\n",
      ", , O\n",
      "including , O\n",
      "Finance , O\n",
      ", , O\n",
      "Accounting , O\n",
      ", , O\n",
      "and , O\n",
      "Customer , O\n",
      "Service , O\n",
      "to , O\n",
      "build , O\n",
      "data , O\n",
      "visualizations , O\n",
      "and , O\n",
      "dashboards , O\n",
      ". , O\n",
      "Essential , O\n",
      "Duties , O\n",
      "And , O\n",
      "ResponsibilitiesDesign , O\n",
      ", , O\n",
      "install , O\n",
      ", , O\n",
      "configure , O\n",
      ", , O\n",
      "and , O\n",
      "maintain , O\n",
      "database , O\n",
      "management , O\n",
      "systems , O\n",
      ". , O\n",
      "Monitor , O\n",
      "database , B\n",
      "performance , I\n",
      "and , O\n",
      "provide , O\n",
      "optimization , O\n",
      ". , O\n",
      "Develop , O\n",
      ", , O\n",
      "implement , O\n",
      ", , O\n",
      "and , O\n",
      "maintain , O\n",
      "backup , O\n",
      "and , O\n",
      "recovery , O\n",
      "procedures , O\n",
      ". , O\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(train_input[0], train_output[0]):\n",
    "    print(i,',',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input = [v for i, v in enumerate(input_tokens) if i in dev_index]\n",
    "dev_output = [v for i, v in enumerate(output_tags) if i in dev_index]\n",
    "\n",
    "test_input = [v for i, v in enumerate(input_tokens) if i in test_index]\n",
    "test_output = [v for i, v in enumerate(output_tags) if i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3669 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input), len(test_input), len(dev_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxsHbKhqrd6-"
   },
   "outputs": [],
   "source": [
    "class SRL_dataset(Dataset):\n",
    "    def __init__(self, input_data, output_data):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        target = self.output_data[index]\n",
    "        data_val = self.input_data[index]\n",
    "        return data_val,target     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxRCQTHard7A"
   },
   "source": [
    "The function below loads a set of files as a `SRL_dataset` in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ldOquKBrd7B"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(input_tokens, output_tags):\n",
    "    '''given a list of Ontonotes SRL, loads them into a pytorch Dataset'''\n",
    "    padded_input_tokens, padded_output_tokens = pad_tokens(input_tokens, LONGEST_SENTENCE), pad_tags(output_tags, LONGEST_SENTENCE)\n",
    "    input_token_tensors, output_tags_tensors = converttokens2tensors(padded_input_tokens), converttags2tensors(padded_output_tokens)\n",
    "    return SRL_dataset(input_token_tensors, output_tags_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assertions to check that everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eoyJ9Rv7rd7D",
    "outputId": "edc60915-24d1-4275-fdf3-3d6e3d11e03f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dev_dataset = prepare_dataset(dev_input, dev_output)\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "train_dataset = prepare_dataset(train_input, train_output)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "for train_token_batch, train_tag_batch in train_dataloader:\n",
    "    assert train_token_batch.shape == torch.Size([batch_size, 2, LONGEST_SENTENCE])\n",
    "    assert train_tag_batch.shape == torch.Size([batch_size, LONGEST_SENTENCE])\n",
    "    break\n",
    "    \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Here are the embedding and hidden dimensionalities as well as LSTM layer count\n",
    "EMBEDDING_DIM=75\n",
    "HIDDEN_DIM=50\n",
    "LAYERS=1\n",
    "\n",
    "# your code here\n",
    "class biLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab, tagset):\n",
    "        super(biLSTMTagger, self).__init__()\n",
    "\n",
    "        # requires vocab, tagset; \n",
    "\n",
    "        self.word_embeddings = nn.Embedding(len(vocab), EMBEDDING_DIM)       # `Embedding` with `len(vocab)` with EMBEDDING_DIM; \n",
    "        #self.indicator_embedding = nn.Embedding(2, EMBEDDING_DIM)   # another `Embedding` for \"indicator_embedding (len(0 or 1)) == 2) with EMBEDDING_DIM ; \n",
    "        #self.lstm = nn.LSTM(2 * EMBEDDING_DIM, HIDDEN_DIM, num_layers=LAYERS, bidirectional = True)                       # `LSTM` with 2 * EMBEDDING_DIM, HIDDEN_DIM, and bidrectional = True\n",
    "\n",
    "        #self.hidden2tag = nn.Linear(2 * HIDDEN_DIM, len(tagset))               # The linear layer that maps from hidden state space to tag space (output = len(tagset))\n",
    "        \n",
    "        #self.indicator_embedding = nn.Embedding(2, EMBEDDING_DIM)   # another `Embedding` for \"indicator_embedding (len(0 or 1)) == 2) with EMBEDDING_DIM ; \n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, num_layers=LAYERS, bidirectional = True)                       # `LSTM` with 2 * EMBEDDING_DIM, HIDDEN_DIM, and bidrectional = True\n",
    "\n",
    "        self.hidden2tag = nn.Linear(2 * HIDDEN_DIM, len(tagset)) \n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch = batch.permute(1, 2, 0)  # required to be permuted: 3 x sent_len x batch_size\n",
    "\n",
    "        #embeds_word = self.word_embeddings(batch[0])\n",
    "        #embeds_ind = self.word_embeddings(batch[1])\n",
    "        #embeds = torch.cat((embeds_word, embeds_ind), dim=2)                        # sent_len x batch_size x 2*EMBEDDING_DIM\n",
    "        embeds = self.word_embeddings(batch[0])\n",
    "        word_lengths = batch[-1].sum(dim=0)\n",
    "        lstm_input =  pack_padded_sequence(embeds, word_lengths, enforce_sorted=False)                            # requires `pack_padded_sequence`\n",
    " \n",
    "        lstm_out, _ = self.lstm(lstm_input)                        # sent_len x batch_size x 2*HIDDEN_DIM\n",
    "        lstm_out, _ =  pad_packed_sequence(lstm_out, total_length = LONGEST_SENTENCE)                          # requires again `pack_padded_sequence` \n",
    "        \n",
    "        tag_space =  self.hidden2tag(lstm_out)                               # generated by `hidden2tag`: sent_len x batch_size x tagset_size\n",
    "        tag_scores = F.log_softmax(tag_space, dim=2)                # then, softmax; \n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An assertion to check your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = biLSTMTagger(WORD_TO_IDX, TAG_TO_IDX)\n",
    "batch = next(iter(train_dataloader))[0]\n",
    "assert tagger(batch).size() == (batch.size()[2], batch_size, len(TAG_TO_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MTLTnzCrd7J"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "EPOCHS = 20 \n",
    "model = biLSTMTagger(WORD_TO_IDX, TAG_TO_IDX)\n",
    "loss_function = nn.CrossEntropyLoss(weight = torch.tensor([0.5, 0.05, 0.4, 0.05]))\n",
    "optimizer = optim.SGD(model.parameters(), lr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0, 'O': 1, 'I': 2, '<null>': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG_TO_IDX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0013678073561910924\n",
      "macro f1 score for dev data: 0.6242859476425062\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.000740359704901368\n",
      "macro f1 score for dev data: 0.6832209577213689\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0006237992206949677\n",
      "macro f1 score for dev data: 0.6915326292365429\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0005502616936453329\n",
      "macro f1 score for dev data: 0.6966632140913931\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0004968399920597158\n",
      "macro f1 score for dev data: 0.7025203124447804\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00045592273065643704\n",
      "macro f1 score for dev data: 0.7016768713259433\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0004229824974980398\n",
      "macro f1 score for dev data: 0.7033686123167607\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00039620090909262093\n",
      "macro f1 score for dev data: 0.7048522180410199\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0003726921294683366\n",
      "macro f1 score for dev data: 0.7059419251702775\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00035180548980735755\n",
      "macro f1 score for dev data: 0.7070491463930506\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00033252839032151124\n",
      "macro f1 score for dev data: 0.7056881740437919\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0003146832881109982\n",
      "macro f1 score for dev data: 0.705796933661043\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002978550910484046\n",
      "macro f1 score for dev data: 0.7117955436353198\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002819597199238066\n",
      "macro f1 score for dev data: 0.7132882376681751\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00026676785085422535\n",
      "macro f1 score for dev data: 0.7122583753446399\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002521750720916316\n",
      "macro f1 score for dev data: 0.7128424675062279\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002380918697875539\n",
      "macro f1 score for dev data: 0.7110352079533475\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [05:24<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00022449417407062418\n",
      "macro f1 score for dev data: 0.7087573159762011\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002114651013408579\n",
      "macro f1 score for dev data: 0.710602044811448\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [05:22<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00019915215094003762\n",
      "macro f1 score for dev data: 0.7118814201305476\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "SENT_PER_BATCH = 4\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    tot_loss = 0\n",
    "    model.train()\n",
    "    for sent_batch, tag_batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.permute(1, 2, 0)\n",
    "        loss = loss_function(tag_scores, tag_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss.item()\n",
    "    # Print the average loss per sentence for the epoch\n",
    "    avg_loss = tot_loss / (len(train_dataloader) * BATCH_SIZE * SENT_PER_BATCH)\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for sent_batch, tag_batch in dev_dataloader:\n",
    "        targets.extend(tag_batch[0].tolist())\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "        preds.extend(tag_scores)\n",
    "    preds = [IDX_TO_TAG[i] for i in preds] \n",
    "    targets = [IDX_TO_TAG[i] for i in targets]\n",
    "    print(f\"Avg loss per sentence: {avg_loss}\")\n",
    "    print('macro f1 score for dev data:',f1_score(targets,preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = prepare_dataset(test_input, test_output)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro f1 score for test data: 0.7213589842627985\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "preds = []\n",
    "for sent_batch, tag_batch in test_dataloader:\n",
    "    targets.extend(tag_batch[0].tolist())\n",
    "    tag_scores = model(sent_batch)\n",
    "    tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "    preds.extend(tag_scores)\n",
    "preds = [IDX_TO_TAG[i] for i in preds] \n",
    "targets = [IDX_TO_TAG[i] for i in targets]\n",
    "print('macro f1 score for test data:',f1_score(targets,preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.46      0.52      0.49      1652\n",
      "           I       0.42      0.39      0.40       396\n",
      "           O       0.99      0.99      0.99    129245\n",
      "\n",
      "   micro avg       0.98      0.98      0.98    131293\n",
      "   macro avg       0.63      0.63      0.63    131293\n",
      "weighted avg       0.98      0.98      0.98    131293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets,preds, labels=['B', 'I', 'O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x296f9b880>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm[1:,1:],\n",
    "                             display_labels = ['B', 'I', 'O'])\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We need someone who is good at Python and Java.\n",
      "Skills: ['Python', 'Java']\n",
      "\n",
      "Input: Good with machine learning. Excellent Azure knowledge. Good with data science and NLP\n",
      "Skills: ['Azure', 'data science', 'NLP']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Some manual testing\n",
    "\n",
    "def get_skills(sentence_list):\n",
    "    prediction = []\n",
    "    token_list = []\n",
    "    tag_list = []\n",
    "    for sentence in sentence_list:\n",
    "        if type(sentence) == str:\n",
    "            doc = nlp(sentence)\n",
    "            tokens = [str(i) for i in doc]\n",
    "            output = ['O' for i in range(len(tokens))]\n",
    "            tokens = tokens[:200]\n",
    "            token_list.append(tokens)\n",
    "            tag_list.append(output)\n",
    "    dataset = prepare_dataset(token_list, tag_list)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    preds = []\n",
    "    for sent_batch, tag_batch in loader:\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "        preds = [IDX_TO_TAG[i] for i in tag_scores] \n",
    "        prediction.append(preds)\n",
    "    #result = []\n",
    "    \n",
    "    entity_list = []\n",
    "    for i, p in enumerate(prediction):\n",
    "        tokens = token_list[i]\n",
    "        entity = ''\n",
    "        entities = []\n",
    "        for j in range(len(p)):\n",
    "            if p[j] == 'B':\n",
    "                if entity != '':\n",
    "                    entities.append(entity)\n",
    "                entity = tokens[j]\n",
    "            elif p[j] == 'I':\n",
    "                if entity != '':\n",
    "                    entity += ' '+tokens[j]\n",
    "            else:\n",
    "                if entity != '':\n",
    "                    entities.append(entity)\n",
    "                entity = ''\n",
    "        entity_list.append(entities)\n",
    "        \n",
    "        #result.append([(t,j) for t, j in zip(tokens, p) if j in {'B', 'I'}])\n",
    "    return  entity_list\n",
    "\n",
    "sentence = ['We need someone who is good at Python and Java.',\n",
    "            \n",
    "'Good with machine learning. Excellent Azure knowledge. Good with data science and NLP',\n",
    "            ]\n",
    "for i,j in zip(sentence,get_skills(sentence)):\n",
    "    print('Input:',i)\n",
    "    print('Skills:',j)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [df['job_segment'][i] for i in test_index if type(df['job_segment'][i])==str]\n",
    "gold = [df['skills'][i] for i in test_index if type(df['job_segment'][i])==str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " 'business, Engineering, technology',\n",
       " nan,\n",
       " nan,\n",
       " 'EVC, monitors, Cybersecurity Engineer',\n",
       " 'Business Analytics',\n",
       " nan,\n",
       " 'Nimble',\n",
       " 'Research Engineer, Machine Learning']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_skills(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['Beeline'],\n",
       " ['Big', 'NLP'],\n",
       " [],\n",
       " ['Cybersecurity',\n",
       "  'Cybersecurity',\n",
       "  'EVC',\n",
       "  'monitors',\n",
       "  'Cybersecurity',\n",
       "  'business'],\n",
       " ['data', 'business', 'data'],\n",
       " [],\n",
       " ['AI', 'AI'],\n",
       " ['Machine Learning']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41523605150214593, 0.5375, 0.4685230024213075)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(gold, pred):\n",
    "    gold_count = 0\n",
    "    pred_count = 0\n",
    "    TP = 0\n",
    "    for i,j in zip(gold, pred):\n",
    "        if type(i) != str:\n",
    "            i = set()\n",
    "        else:\n",
    "            i = set([s.strip().lower() for s in i.split(',')])\n",
    "        j = set([i.lower() for i in j])\n",
    "        TP += len(i.intersection(j))\n",
    "        gold_count += len(i)\n",
    "        pred_count += len(j)\n",
    "    prec = TP / pred_count\n",
    "    recall = TP / gold_count\n",
    "    f1 = 2 * prec * recall / (prec + recall)\n",
    "    return prec, recall, f1\n",
    "\n",
    "evaluate(gold, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on human annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def jd_clean(job):\n",
    "    return ' '.join(re.split(r'[\\'\\\"], [\\'\\\"]', job[2:-2]))\n",
    "\n",
    "df_eval = pd.read_csv('final_annotated_data.csv')\n",
    "df_eval['job'] = df_eval['job_description'].apply(jd_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>class_name</th>\n",
       "      <th>experience</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>Full Stack Software Engineer</td>\n",
       "      <td>['SpaceX was founded under the belief that a f...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>sql,python,server,react,database,scala,c#.net,...</td>\n",
       "      <td>full_stack_engineer</td>\n",
       "      <td>junior</td>\n",
       "      <td>SpaceX was founded under the belief that a fut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "      <td>Intermediate Full-Stack Web Developer (C#/MSSQ...</td>\n",
       "      <td>['Splashdot is looking for a Intermediate Full...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>asp net,asp.net,sql,c#,server,realm,html/css,r...</td>\n",
       "      <td>full_stack_engineer</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>Splashdot is looking for a Intermediate Full-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "      <td>Frontend Software Engineer</td>\n",
       "      <td>[\"ResponsibilitiesFounded in 2012, ByteDance's...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>ambiguity,sql,server,swift,broadcasting,react,...</td>\n",
       "      <td>full_stack_engineer</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>ResponsibilitiesFounded in 2012, ByteDance's m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>['About The JobTome is building across a broad...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>postgresql,typescript,react,node</td>\n",
       "      <td>full_stack_engineer</td>\n",
       "      <td>junior</td>\n",
       "      <td>About The JobTome is building across a broad s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "      <td>Full Stack Developer (Remote)</td>\n",
       "      <td>['MonetizeMore builds industry-leading ad tech...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>git,python,react,deployment,node,linux,ruby,sc...</td>\n",
       "      <td>full_stack_engineer</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>MonetizeMore builds industry-leading ad techno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "1  https://www.linkedin.com/jobs/view/associate-d...   \n",
       "2  https://www.linkedin.com/jobs/view/associate-d...   \n",
       "3  https://www.linkedin.com/jobs/view/associate-d...   \n",
       "4  https://www.linkedin.com/jobs/view/associate-d...   \n",
       "\n",
       "                                               title  \\\n",
       "0                       Full Stack Software Engineer   \n",
       "1  Intermediate Full-Stack Web Developer (C#/MSSQ...   \n",
       "2                         Frontend Software Engineer   \n",
       "3                                Full Stack Engineer   \n",
       "4                      Full Stack Developer (Remote)   \n",
       "\n",
       "                                     job_description   seniority_level  \\\n",
       "0  ['SpaceX was founded under the belief that a f...       Entry level   \n",
       "1  ['Splashdot is looking for a Intermediate Full...    Not Applicable   \n",
       "2  [\"ResponsibilitiesFounded in 2012, ByteDance's...  Mid-Senior level   \n",
       "3  ['About The JobTome is building across a broad...       Entry level   \n",
       "4  ['MonetizeMore builds industry-leading ad tech...  Mid-Senior level   \n",
       "\n",
       "  employment_type                                             skills  \\\n",
       "0       Full-time  sql,python,server,react,database,scala,c#.net,...   \n",
       "1       Full-time  asp net,asp.net,sql,c#,server,realm,html/css,r...   \n",
       "2       Full-time  ambiguity,sql,server,swift,broadcasting,react,...   \n",
       "3       Full-time                   postgresql,typescript,react,node   \n",
       "4       Full-time  git,python,react,deployment,node,linux,ruby,sc...   \n",
       "\n",
       "            class_name    experience  \\\n",
       "0  full_stack_engineer        junior   \n",
       "1  full_stack_engineer  intermediate   \n",
       "2  full_stack_engineer  intermediate   \n",
       "3  full_stack_engineer        junior   \n",
       "4  full_stack_engineer  intermediate   \n",
       "\n",
       "                                                 job  \n",
       "0  SpaceX was founded under the belief that a fut...  \n",
       "1  Splashdot is looking for a Intermediate Full-S...  \n",
       "2  ResponsibilitiesFounded in 2012, ByteDance's m...  \n",
       "3  About The JobTome is building across a broad s...  \n",
       "4  MonetizeMore builds industry-leading ad techno...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def get_token_number(text):\n",
    "    doc = nlp(text)\n",
    "    return len([i for i in doc])\n",
    "\n",
    "\n",
    "def sentence_segmentation(job_desc):\n",
    "    \"\"\"\n",
    "    This function return a list of sentences for a job description\n",
    "    \"\"\"\n",
    "    doc = nlp(job_desc)\n",
    "    return [sent for sent in doc.sents]\n",
    "\n",
    "\n",
    "def get_paras(sents, skills_list, limit = 128):\n",
    "    '''\n",
    "    Converts a list of sentences to a list of paragraphs (so that we could limit the number of API calls to some extent)\n",
    "    '''\n",
    "    num_token = 0\n",
    "    paragraphs = []\n",
    "    sub_skills = []\n",
    "    para = ''\n",
    "    for sent in sents:\n",
    "        sent = sent.text\n",
    "        num_token += get_token_number(sent)\n",
    "        if num_token >= limit:\n",
    "            paragraphs.append(para)\n",
    "            sub_skills.append(', '.join([i for i in skills_list if i in para.lower()]))\n",
    "            para = ''\n",
    "            num_token = 0\n",
    "        para += ' ' + sent\n",
    "    paragraphs.append(para)\n",
    "    sub_skills.append(', '.join([i for i in skills_list if i in para]))\n",
    "    return paragraphs, sub_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "278it [00:48,  5.75it/s]\n"
     ]
    }
   ],
   "source": [
    "paras_list = []\n",
    "skills_list = []\n",
    "job_id = []\n",
    "i = 0\n",
    "for job, skills in tqdm(zip(df_eval['job'], df_eval['skills'])):\n",
    "    sents = sentence_segmentation(job)\n",
    "    skills_list_temp = [i.strip() for i in skills.split(',')]\n",
    "    paras, skill = get_paras(sents, skills_list_temp, limit = 128)\n",
    "    paras_list.extend(paras)\n",
    "    skills_list.extend(skill)\n",
    "    job_id.extend([i for j in range(len(skill))])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_segment</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpaceX was founded under the belief that a fu...</td>\n",
       "      <td>software, go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>We design, build, test, and operate all parts...</td>\n",
       "      <td>software, engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>On this team, we will rely on you to be a key...</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Develop well-architected, responsive, and per...</td>\n",
       "      <td>sql, python, server, react, database, scala, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Base salary is just one part of your total re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>276</td>\n",
       "      <td>We work to build each other up and support on...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>276</td>\n",
       "      <td>Throughout the year, the advantage of being p...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>277</td>\n",
       "      <td>Cybersecurity Specialist â€“ Network and Comm...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>277</td>\n",
       "      <td>This role will give you the opportunity to in...</td>\n",
       "      <td>iso, nist, iam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>277</td>\n",
       "      <td>OpportunitiesDevelop your skills within the s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1090 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_id                                        job_segment  \\\n",
       "0          0   SpaceX was founded under the belief that a fu...   \n",
       "1          0   We design, build, test, and operate all parts...   \n",
       "2          0   On this team, we will rely on you to be a key...   \n",
       "3          0   Develop well-architected, responsive, and per...   \n",
       "4          0   Base salary is just one part of your total re...   \n",
       "...      ...                                                ...   \n",
       "1085     276   We work to build each other up and support on...   \n",
       "1086     276   Throughout the year, the advantage of being p...   \n",
       "1087     277   Cybersecurity Specialist â€“ Network and Comm...   \n",
       "1088     277   This role will give you the opportunity to in...   \n",
       "1089     277   OpportunitiesDevelop your skills within the s...   \n",
       "\n",
       "                                                 skills  \n",
       "0                                          software, go  \n",
       "1                                 software, engineering  \n",
       "2                                              software  \n",
       "3     sql, python, server, react, database, scala, c...  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "1085                                                     \n",
       "1086                                                     \n",
       "1087                                                     \n",
       "1088                                     iso, nist, iam  \n",
       "1089                                                     \n",
       "\n",
       "[1090 rows x 3 columns]"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = pd.DataFrame({'job_id': job_id, 'job_segment':paras_list, 'skills':skills_list})\n",
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = df_split[df_split['job_segment']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 259 ms, total: 25.2 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_skills = get_skills(df_split['job_segment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/1dfn6jyd4m1chbgpv0qm29nw0000gn/T/ipykernel_26741/1370963735.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_split['prediction'] = [','.join(p).lower() for p in pred_skills]\n"
     ]
    }
   ],
   "source": [
    "df_split['prediction'] = [','.join(p).lower() for p in pred_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.27315914489311166\n",
      "Recall: 0.23354995938261575\n",
      "F1: 0.2518064374863148\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "len_gold = 0\n",
    "len_pred = 0\n",
    "for i in df_split['job_id'].unique():\n",
    "    temp = df_split[df_split['job_id']==i]\n",
    "    gold = ','.join(temp['skills'])\n",
    "    pred = ','.join(temp['prediction'])\n",
    "    gold = set([i.strip() for i in gold.split(',') if i.strip()!=''])\n",
    "    pred = set([i.strip() for i in pred.split(',') if i.strip()!=''])\n",
    "    TP += len(gold.intersection(pred))\n",
    "    len_gold += len(gold)\n",
    "    len_pred += len(pred)\n",
    "prec = TP / len_pred\n",
    "recall = TP / len_gold\n",
    "f1 = 2 * prec * recall / (prec + recall)\n",
    "print('Precision:', prec)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6679it [04:36, 24.13it/s]\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "all_tags = []\n",
    "for job, skills in tqdm(zip(df['job_segment'], df['skills'])):\n",
    "    tokens, tags = get_tags(job, skills)\n",
    "    inputs = [(i, int(i.istitle()), int(i.isupper()), int(i.islower())) for i in tokens]\n",
    "    all_inputs.append(inputs)\n",
    "    all_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5669"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens, output_tags = [], []\n",
    "for i, j in zip(all_inputs, all_tags):\n",
    "    if len(i) <= LONGEST_SENTENCE:\n",
    "        input_tokens.append(i)\n",
    "        output_tags.append(j)\n",
    "len(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SummaryThe', 0, 0, 0),\n",
       " ('Database', 1, 0, 0),\n",
       " ('Developer', 1, 0, 0),\n",
       " ('is', 0, 0, 1),\n",
       " ('part', 0, 0, 1)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(input_tokens, longest_sentence):\n",
    "    padded = []\n",
    "    for sent in input_tokens:\n",
    "        padding = [(\"<null>\", \"<null>\", \"<null>\", \"<null>\") for i in range(longest_sentence - len(sent))]\n",
    "        padded.append(sent + padding)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttokens2tensors(input_tokens):\n",
    "    '''\n",
    "        Convert input_tokens into a tensor\n",
    "        \n",
    "        input:  A list of sentences consisting of (token, is_target_pred) pairs.\n",
    "        output: A list of 2 x sentence_length tensor t\n",
    "        \n",
    "        where t[0][i] gives the index number for token i, t[1][i] is either 0 or 1 \n",
    "        depending on is_target_pred and t[2][i] indicates whether this is a regular\n",
    "        token or padding token PAD.\n",
    "    '''\n",
    "    token_tensors = []\n",
    "    #your code here\n",
    "    unk = WORD_TO_IDX[\"<unk>\"]\n",
    "\n",
    "    for sent in input_tokens:\n",
    "        tokens = [i[0] for i in sent]\n",
    "        is_title = [i[1] if i[1]!='<null>' else 2 for i in sent]\n",
    "        is_capital = [i[2] if i[2]!='<null>' else 2 for i in sent]\n",
    "        is_lower = [i[3] if i[3]!='<null>' else 2 for i in sent]\n",
    "        ids = [WORD_TO_IDX[token] if token in WORD_TO_IDX else WORD_TO_IDX['<unk>'] for token in tokens]\n",
    "        pad_status = [1 if i[0]!='<null>' else 0 for i in tokens]\n",
    "        #print(ids, is_title, is_capital, is_lower, pad_status)\n",
    "        t =  torch.tensor([ids, is_title, is_capital, is_lower, pad_status])\n",
    "        token_tensors.append(t)\n",
    "    \n",
    "    return token_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = [v for i, v in enumerate(input_tokens) if i not in test_dev_index]\n",
    "train_output = [v for i, v in enumerate(output_tags) if i not in test_dev_index]\n",
    "\n",
    "dev_input = [v for i, v in enumerate(input_tokens) if i in dev_index]\n",
    "dev_output = [v for i, v in enumerate(output_tags) if i in dev_index]\n",
    "\n",
    "test_input = [v for i, v in enumerate(input_tokens) if i in test_index]\n",
    "test_output = [v for i, v in enumerate(output_tags) if i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dev_dataset = prepare_dataset(dev_input, dev_output)\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "train_dataset = prepare_dataset(train_input, train_output)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "for train_token_batch, train_tag_batch in train_dataloader:\n",
    "    assert train_token_batch.shape == torch.Size([batch_size, 5, LONGEST_SENTENCE])\n",
    "    assert train_tag_batch.shape == torch.Size([batch_size, LONGEST_SENTENCE])\n",
    "    break\n",
    "    \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Here are the embedding and hidden dimensionalities as well as LSTM layer count\n",
    "EMBEDDING_DIM=75\n",
    "SMALL_EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM=50\n",
    "LAYERS=1\n",
    "\n",
    "# your code here\n",
    "class biLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab, tagset):\n",
    "        super(biLSTMTagger, self).__init__()\n",
    "\n",
    "        # requires vocab, tagset; \n",
    "\n",
    "        self.word_embeddings = nn.Embedding(len(vocab), EMBEDDING_DIM)       # `Embedding` with `len(vocab)` with EMBEDDING_DIM; \n",
    "        self.title_embedding = nn.Embedding(3, SMALL_EMBEDDING_DIM)   # another `Embedding` for \"indicator_embedding (len(0 or 1)) == 2) with EMBEDDING_DIM ; \n",
    "        self.capital_embedding = nn.Embedding(3, SMALL_EMBEDDING_DIM)\n",
    "        self.lower_embedding = nn.Embedding(3, SMALL_EMBEDDING_DIM)\n",
    "        #self.lstm = nn.LSTM(2 * EMBEDDING_DIM, HIDDEN_DIM, num_layers=LAYERS, bidirectional = True)                       # `LSTM` with 2 * EMBEDDING_DIM, HIDDEN_DIM, and bidrectional = True\n",
    "\n",
    "        #self.hidden2tag = nn.Linear(2 * HIDDEN_DIM, len(tagset))               # The linear layer that maps from hidden state space to tag space (output = len(tagset))\n",
    "        \n",
    "        #self.indicator_embedding = nn.Embedding(2, EMBEDDING_DIM)   # another `Embedding` for \"indicator_embedding (len(0 or 1)) == 2) with EMBEDDING_DIM ; \n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM + 3 * SMALL_EMBEDDING_DIM, HIDDEN_DIM, num_layers=LAYERS, bidirectional = True)                       # `LSTM` with 2 * EMBEDDING_DIM, HIDDEN_DIM, and bidrectional = True\n",
    "\n",
    "        self.hidden2tag = nn.Linear(2 * HIDDEN_DIM, len(tagset)) \n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch = batch.permute(1, 2, 0)  # required to be permuted: 3 x sent_len x batch_size\n",
    "\n",
    "        #embeds_word = self.word_embeddings(batch[0])\n",
    "        #embeds_ind = self.word_embeddings(batch[1])\n",
    "        #embeds = torch.cat((embeds_word, embeds_ind), dim=2)                        # sent_len x batch_size x 2*EMBEDDING_DIM\n",
    "        embeds_word = self.word_embeddings(batch[0])\n",
    "        embeds_title = self.title_embedding(batch[1])\n",
    "        embeds_capital = self.capital_embedding(batch[2])\n",
    "        embeds_lower = self.lower_embedding(batch[3])\n",
    "        embeds = torch.cat((embeds_word, embeds_title, embeds_capital, embeds_lower), dim=2) \n",
    "        word_lengths = batch[-1].sum(dim=0)\n",
    "        lstm_input =  pack_padded_sequence(embeds, word_lengths, enforce_sorted=False)                            # requires `pack_padded_sequence`\n",
    " \n",
    "        lstm_out, _ = self.lstm(lstm_input)                        # sent_len x batch_size x 2*HIDDEN_DIM\n",
    "        lstm_out, _ =  pad_packed_sequence(lstm_out, total_length = LONGEST_SENTENCE)                          # requires again `pack_padded_sequence` \n",
    "        \n",
    "        tag_space =  self.hidden2tag(lstm_out)                               # generated by `hidden2tag`: sent_len x batch_size x tagset_size\n",
    "        tag_scores = F.log_softmax(tag_space, dim=2)                # then, softmax; \n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "EPOCHS = 20 \n",
    "model = biLSTMTagger(WORD_TO_IDX, TAG_TO_IDX)\n",
    "loss_function = nn.CrossEntropyLoss(weight = torch.tensor([0.5, 0.05, 0.4, 0.05]))\n",
    "optimizer = optim.SGD(model.parameters(), lr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0009753545846565273\n",
      "macro f1 score for dev data: 0.6809434989551382\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0005921428543435217\n",
      "macro f1 score for dev data: 0.6868706368049946\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0005179991517095538\n",
      "macro f1 score for dev data: 0.7013654005184906\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0004683632116588154\n",
      "macro f1 score for dev data: 0.7163325157490211\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00043179755849795864\n",
      "macro f1 score for dev data: 0.7223161863263432\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:22<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0004028752109975201\n",
      "macro f1 score for dev data: 0.7255407828625914\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:25<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00037854696560755437\n",
      "macro f1 score for dev data: 0.7256003732229488\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:26<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0003572873854487813\n",
      "macro f1 score for dev data: 0.7297349937426335\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:25<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00033819863943037866\n",
      "macro f1 score for dev data: 0.7316558243687872\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:25<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00032078668200170044\n",
      "macro f1 score for dev data: 0.7329995213754446\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:26<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0003048359127394084\n",
      "macro f1 score for dev data: 0.7321786597580635\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:24<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002900862941871686\n",
      "macro f1 score for dev data: 0.733333613755833\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002763107253925008\n",
      "macro f1 score for dev data: 0.7348903715021269\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00026338166684707114\n",
      "macro f1 score for dev data: 0.7352347105778164\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00025122299848590046\n",
      "macro f1 score for dev data: 0.7373859048713871\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00023968720704252864\n",
      "macro f1 score for dev data: 0.7403956627335065\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:24<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00022870327816706086\n",
      "macro f1 score for dev data: 0.7426532053855673\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.0002182245163943474\n",
      "macro f1 score for dev data: 0.7431266775152627\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:23<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00020818718584105853\n",
      "macro f1 score for dev data: 0.7442813949334465\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:25<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss per sentence: 0.00019854516308285007\n",
      "macro f1 score for dev data: 0.7458872962798395\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "SENT_PER_BATCH = 4\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    tot_loss = 0\n",
    "    model.train()\n",
    "    for sent_batch, tag_batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.permute(1, 2, 0)\n",
    "        loss = loss_function(tag_scores, tag_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss.item()\n",
    "    # Print the average loss per sentence for the epoch\n",
    "    avg_loss = tot_loss / (len(train_dataloader) * BATCH_SIZE * SENT_PER_BATCH)\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for sent_batch, tag_batch in dev_dataloader:\n",
    "        targets.extend(tag_batch[0].tolist())\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "        preds.extend(tag_scores)\n",
    "    preds = [IDX_TO_TAG[i] for i in preds] \n",
    "    targets = [IDX_TO_TAG[i] for i in targets]\n",
    "    print(f\"Avg loss per sentence: {avg_loss}\")\n",
    "    print('macro f1 score for dev data:',f1_score(targets,preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = prepare_dataset(test_input, test_output)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro f1 score for test data: 0.7343961409167863\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "preds = []\n",
    "for sent_batch, tag_batch in test_dataloader:\n",
    "    targets.extend(tag_batch[0].tolist())\n",
    "    tag_scores = model(sent_batch)\n",
    "    tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "    preds.extend(tag_scores)\n",
    "preds = [IDX_TO_TAG[i] for i in preds] \n",
    "targets = [IDX_TO_TAG[i] for i in targets]\n",
    "print('macro f1 score for test data:',f1_score(targets,preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.44      0.55      0.49      1682\n",
      "           I       0.41      0.52      0.46       405\n",
      "           O       0.99      0.99      0.99    129879\n",
      "\n",
      "   micro avg       0.98      0.98      0.98    131966\n",
      "   macro avg       0.61      0.69      0.65    131966\n",
      "weighted avg       0.98      0.98      0.98    131966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets,preds, labels=['B', 'I', 'O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We need someone who is good at Python and Java.\n",
      "Skills: ['Python', 'Java']\n",
      "\n",
      "Input: We need someone who is good at python and java.\n",
      "Skills: ['python']\n",
      "\n",
      "Input: Good with machine learning. Excellent Azure knowledge. Good with data science and NLP\n",
      "Skills: ['machine learning', 'Azure', 'data science']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Some manual testing\n",
    "\n",
    "def get_skills(sentence_list):\n",
    "    prediction = []\n",
    "    token_list = []\n",
    "    tag_list = []\n",
    "    for sentence in sentence_list:\n",
    "        doc = nlp(sentence)\n",
    "        tokens = [(str(i), int(str(i).istitle()),int(str(i).isupper()), int(str(i).islower())) for i in doc]\n",
    "        output = ['O' for i in range(len(tokens))]\n",
    "        tokens = tokens[:200]\n",
    "        token_list.append(tokens)\n",
    "        tag_list.append(output)\n",
    "    dataset = prepare_dataset(token_list, tag_list)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    preds = []\n",
    "    for sent_batch, tag_batch in loader:\n",
    "        tag_scores = model(sent_batch)\n",
    "        tag_scores = tag_scores.argmax(axis=2).squeeze().tolist()\n",
    "        preds = [IDX_TO_TAG[i] for i in tag_scores] \n",
    "        prediction.append(preds)\n",
    "    #result = []\n",
    "    \n",
    "    entity_list = []\n",
    "    for i, p in enumerate(prediction):\n",
    "        tokens = [w[0] for w in token_list[i]]\n",
    "        entity = ''\n",
    "        entities = []\n",
    "        for j in range(len(p)):\n",
    "            if p[j] == 'B':\n",
    "                if entity != '':\n",
    "                    entities.append(entity)\n",
    "                entity = tokens[j]\n",
    "            elif p[j] == 'I':\n",
    "                if entity != '':\n",
    "                    entity += ' '+tokens[j]\n",
    "            else:\n",
    "                if entity != '':\n",
    "                    entities.append(entity)\n",
    "                entity = ''\n",
    "        entity_list.append(entities)\n",
    "        \n",
    "        #result.append([(t,j) for t, j in zip(tokens, p) if j in {'B', 'I'}])\n",
    "    return  entity_list\n",
    "\n",
    "sentence = ['We need someone who is good at Python and Java.',\n",
    "            'We need someone who is good at python and java.',\n",
    "            \n",
    "'Good with machine learning. Excellent Azure knowledge. Good with data science and NLP',\n",
    "            ]\n",
    "for i,j in zip(sentence,get_skills(sentence)):\n",
    "    print('Input:',i)\n",
    "    print('Skills:',j)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 s, sys: 442 ms, total: 28.2 s\n",
      "Wall time: 28.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['data'], [], [], [], ['Racing', 'AWS']]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictions = get_skills(sentence_list)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3787076271186441, 0.5088967971530249, 0.43425447919829946)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gold, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lab2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
